{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import resample\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here, we load the dataset and drop some unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26816, 58)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dri_score</th>\n",
       "      <th>psych_disturb</th>\n",
       "      <th>cyto_score</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>hla_match_c_high</th>\n",
       "      <th>hla_high_res_8</th>\n",
       "      <th>tbi_status</th>\n",
       "      <th>arrhythmia</th>\n",
       "      <th>hla_low_res_6</th>\n",
       "      <th>graft_type</th>\n",
       "      <th>...</th>\n",
       "      <th>hepatic_mild</th>\n",
       "      <th>tce_div_match</th>\n",
       "      <th>donor_related</th>\n",
       "      <th>melphalan_dose</th>\n",
       "      <th>hla_low_res_8</th>\n",
       "      <th>cardiac</th>\n",
       "      <th>hla_match_drb1_high</th>\n",
       "      <th>pulm_moderate</th>\n",
       "      <th>hla_low_res_10</th>\n",
       "      <th>efs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intermediate</td>\n",
       "      <td>No</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>TBI +- Other, &gt;cGy</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Peripheral blood</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Permissive mismatched</td>\n",
       "      <td>Related</td>\n",
       "      <td>N/A, Mel not given</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Intermediate</td>\n",
       "      <td>No</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Peripheral blood</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>GvH non-permissive</td>\n",
       "      <td>Unrelated</td>\n",
       "      <td>N/A, Mel not given</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Intermediate</td>\n",
       "      <td>No</td>\n",
       "      <td>Intermediate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Peripheral blood</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Permissive mismatched</td>\n",
       "      <td>Unrelated</td>\n",
       "      <td>N/A, Mel not given</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>High</td>\n",
       "      <td>No</td>\n",
       "      <td>Poor</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Peripheral blood</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>Permissive mismatched</td>\n",
       "      <td>Unrelated</td>\n",
       "      <td>MEL</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N/A - pediatric</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No TBI</td>\n",
       "      <td>No</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Bone marrow</td>\n",
       "      <td>...</td>\n",
       "      <td>No</td>\n",
       "      <td>None</td>\n",
       "      <td>Related</td>\n",
       "      <td>MEL</td>\n",
       "      <td>8.0</td>\n",
       "      <td>No</td>\n",
       "      <td>2.0</td>\n",
       "      <td>No</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         dri_score psych_disturb    cyto_score diabetes  hla_match_c_high  \\\n",
       "0     Intermediate            No  Intermediate       No               2.0   \n",
       "1     Intermediate            No  Intermediate       No               2.0   \n",
       "2     Intermediate            No  Intermediate      Yes               2.0   \n",
       "3             High            No          Poor      Yes               2.0   \n",
       "4  N/A - pediatric            No          None       No               2.0   \n",
       "\n",
       "   hla_high_res_8          tbi_status arrhythmia  hla_low_res_6  \\\n",
       "0             8.0  TBI +- Other, >cGy         No            6.0   \n",
       "1             8.0              No TBI         No            6.0   \n",
       "2             8.0              No TBI         No            6.0   \n",
       "3             8.0              No TBI         No            6.0   \n",
       "4             8.0              No TBI         No            6.0   \n",
       "\n",
       "         graft_type  ... hepatic_mild          tce_div_match donor_related  \\\n",
       "0  Peripheral blood  ...           No  Permissive mismatched       Related   \n",
       "1  Peripheral blood  ...           No     GvH non-permissive     Unrelated   \n",
       "2  Peripheral blood  ...           No  Permissive mismatched     Unrelated   \n",
       "3  Peripheral blood  ...           No  Permissive mismatched     Unrelated   \n",
       "4       Bone marrow  ...           No                   None       Related   \n",
       "\n",
       "       melphalan_dose  hla_low_res_8 cardiac  hla_match_drb1_high  \\\n",
       "0  N/A, Mel not given            8.0      No                  2.0   \n",
       "1  N/A, Mel not given            8.0      No                  2.0   \n",
       "2  N/A, Mel not given            8.0     Yes                  2.0   \n",
       "3                 MEL            8.0      No                  2.0   \n",
       "4                 MEL            8.0      No                  2.0   \n",
       "\n",
       "   pulm_moderate hla_low_res_10  efs  \n",
       "0            Yes           10.0  1.0  \n",
       "1             No            9.0  1.0  \n",
       "2             No           10.0  1.0  \n",
       "3            Yes           10.0  1.0  \n",
       "4             No           10.0  1.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"train.parquet\")\n",
    "df.drop(columns=[\"ID\", \"efs_time\"], axis=1, inplace=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13406, 58)\n",
      "(11076, 58)\n",
      "(1659, 58)\n",
      "(675, 58)\n"
     ]
    }
   ],
   "source": [
    "print(df[(df[\"ethnicity\"] == \"Not Hispanic or Latino\") & (df[\"efs\"] == 1)].shape)\n",
    "print(df[(df[\"ethnicity\"] == \"Not Hispanic or Latino\") & (df[\"efs\"] == 0)].shape)\n",
    "print(df[(df[\"ethnicity\"] == \"Hispanic or Latino\") & (df[\"efs\"] == 1)].shape)\n",
    "print(df[(df[\"ethnicity\"] == \"Hispanic or Latino\") & (df[\"efs\"] == 0)].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we do some fillna operations for the null values and use labelencoder for simple features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In these features, there are 35 CATEGORICAL FEATURES: ['dri_score', 'psych_disturb', 'cyto_score', 'diabetes', 'tbi_status', 'arrhythmia', 'graft_type', 'vent_hist', 'renal_issue', 'pulm_severe', 'prim_disease_hct', 'cmv_status', 'tce_imm_match', 'rituximab', 'prod_type', 'cyto_score_detail', 'conditioning_intensity', 'ethnicity', 'obesity', 'mrd_hct', 'in_vivo_tcd', 'tce_match', 'hepatic_severe', 'prior_tumor', 'peptic_ulcer', 'gvhd_proph', 'rheum_issue', 'sex_match', 'race_group', 'hepatic_mild', 'tce_div_match', 'donor_related', 'melphalan_dose', 'cardiac', 'pulm_moderate']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dri_score</th>\n",
       "      <th>psych_disturb</th>\n",
       "      <th>cyto_score</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>hla_match_c_high</th>\n",
       "      <th>hla_high_res_8</th>\n",
       "      <th>tbi_status</th>\n",
       "      <th>arrhythmia</th>\n",
       "      <th>hla_low_res_6</th>\n",
       "      <th>graft_type</th>\n",
       "      <th>...</th>\n",
       "      <th>hepatic_mild</th>\n",
       "      <th>tce_div_match</th>\n",
       "      <th>donor_related</th>\n",
       "      <th>melphalan_dose</th>\n",
       "      <th>hla_low_res_8</th>\n",
       "      <th>cardiac</th>\n",
       "      <th>hla_match_drb1_high</th>\n",
       "      <th>pulm_moderate</th>\n",
       "      <th>hla_low_res_10</th>\n",
       "      <th>efs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dri_score  psych_disturb  cyto_score  diabetes  hla_match_c_high  \\\n",
       "0          2              0           1         0               2.0   \n",
       "1          2              0           1         0               2.0   \n",
       "2          2              0           1         3               2.0   \n",
       "3          0              0           6         3               2.0   \n",
       "4          8              0           2         0               2.0   \n",
       "\n",
       "   hla_high_res_8  tbi_status  arrhythmia  hla_low_res_6  graft_type  ...  \\\n",
       "0             8.0           6           0            6.0           1  ...   \n",
       "1             8.0           0           0            6.0           1  ...   \n",
       "2             8.0           0           0            6.0           1  ...   \n",
       "3             8.0           0           0            6.0           1  ...   \n",
       "4             8.0           0           0            6.0           0  ...   \n",
       "\n",
       "   hepatic_mild  tce_div_match  donor_related  melphalan_dose  hla_low_res_8  \\\n",
       "0             0              4              2               1            8.0   \n",
       "1             0              1              3               1            8.0   \n",
       "2             0              4              3               1            8.0   \n",
       "3             0              4              3               0            8.0   \n",
       "4             0              3              2               0            8.0   \n",
       "\n",
       "   cardiac  hla_match_drb1_high  pulm_moderate  hla_low_res_10  efs  \n",
       "0        0                  2.0              3            10.0    1  \n",
       "1        0                  2.0              0             9.0    1  \n",
       "2        3                  2.0              0            10.0    1  \n",
       "3        0                  2.0              3            10.0    1  \n",
       "4        0                  2.0              0            10.0    1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_cols = []\n",
    "num_cols = []\n",
    "\n",
    "TARGET = [\"efs\"]\n",
    "FEATURES = [c for c in df.columns if c not in TARGET]\n",
    "\n",
    "for c in FEATURES:\n",
    "    if df[c].dtype == \"object\" or df[c].dtype == \"category\":\n",
    "        cat_cols.append(c)\n",
    "    else:\n",
    "        num_cols.append(c)\n",
    "print(f\"In these features, there are {len(cat_cols)} CATEGORICAL FEATURES: {cat_cols}\")\n",
    "\n",
    "\n",
    "def update(df, cat_cols):\n",
    "    for c in cat_cols:\n",
    "        df[c] = df[c].astype(str).fillna(\"Unknown\").astype(\"category\")\n",
    "    for c in num_cols:\n",
    "        if df[c].dtype == \"float64\":\n",
    "            df[c] = df[c].fillna(0).astype(\"float32\")\n",
    "        if df[c].dtype == \"int64\":\n",
    "            df[c] = df[c].fillna(0).astype(\"int32\")\n",
    "    return df\n",
    "\n",
    "df[\"efs\"] = df[\"efs\"].astype(\"int32\")\n",
    "df = update(df, cat_cols)\n",
    "for col in cat_cols:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col].astype(str))\n",
    "df.sample(frac=1.0).reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we set the sensitive attribute to be \"ethnicity\" and split the dataset into df and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ethnicity\n",
       "1    24482\n",
       "0     2334\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"ethnicity\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "(24134, 57) (24134,)\n",
      "(2682, 57) (2682,)\n"
     ]
    }
   ],
   "source": [
    "features = [c for c in df.columns if c not in TARGET]\n",
    "sensitive_attribute = features.index(\"ethnicity\")\n",
    "print(sensitive_attribute)\n",
    "\n",
    "target = [\"efs\"]\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "X_train_df, X_test_df, y_train_df, y_test_df = train_test_split(X, y, test_size=0.1, shuffle=True, random_state=42)\n",
    "\n",
    "X_train = X_train_df.to_numpy()\n",
    "X_test = X_test_df.to_numpy()\n",
    "y_train = y_train_df.to_numpy().ravel()\n",
    "y_test = y_test_df.to_numpy().ravel()\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we report the per-group prevalance for z=0 and z=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.726890756302521, 0.5495090016366612)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_test = (X_test[:, sensitive_attribute] == 1)\n",
    "\n",
    "prevalence_0 = np.mean(y_test[z_test == 0])\n",
    "prevalence_1 = np.mean(y_test[z_test == 1])\n",
    "\n",
    "prevalence_0, prevalence_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we train the basic model and report the demographic parity on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2333074822849495"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=1, max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "z_test = (X_test[:, sensitive_attribute] == 1)\n",
    "\n",
    "positive_pred_z_0 = np.mean(y_pred[z_test == 0])\n",
    "positive_pred_z_1 = np.mean(y_pred[z_test == 1])\n",
    "\n",
    "parity = positive_pred_z_0 / positive_pred_z_1\n",
    "parity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here we report TPR_0, TPR_1, FPR_0, and FPR_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8323699421965318, 0.7840655249441548, 0.7076923076923077, 0.48047229791099)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_test = (X_test[:, sensitive_attribute] == 1)\n",
    "\n",
    "tp_0 = np.sum((y_pred == 1) & (y_test == 1) & (z_test == 0))\n",
    "fn_0 = np.sum((y_pred == 0) & (y_test == 1) & (z_test == 0))\n",
    "fp_0 = np.sum((y_pred == 1) & (y_test == 0) & (z_test == 0))\n",
    "tn_0 = np.sum((y_pred == 0) & (y_test == 0) & (z_test == 0))\n",
    "\n",
    "tp_1 = np.sum((y_pred == 1) & (y_test == 1) & (z_test == 1))\n",
    "fn_1 = np.sum((y_pred == 0) & (y_test == 1) & (z_test == 1))\n",
    "fp_1 = np.sum((y_pred == 1) & (y_test == 0) & (z_test == 1))\n",
    "tn_1 = np.sum((y_pred == 0) & (y_test == 0) & (z_test == 1))\n",
    "\n",
    "TPR_0 = tp_0 / (tp_0 + fn_0)\n",
    "TPR_1 = tp_1 / (tp_1 + fn_1)\n",
    "\n",
    "FPR_0 = fp_0 / (fp_0 + tn_0)\n",
    "FPR_1 = fp_1 / (fp_1 + tn_1)\n",
    "\n",
    "TPR_0, TPR_1, FPR_0, FPR_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we try data-based method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12063, 58)\n",
      "(9975, 58)\n",
      "(1486, 58)\n",
      "(610, 58)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.concat([X_train_df, y_train_df], axis=1)\n",
    "\n",
    "print(train_df[(train_df[\"ethnicity\"] == 1) & (train_df[\"efs\"] == 1)].shape)\n",
    "print(train_df[(train_df[\"ethnicity\"] == 1) & (train_df[\"efs\"] == 0)].shape)\n",
    "print(train_df[(train_df[\"ethnicity\"] == 0) & (train_df[\"efs\"] == 1)].shape)\n",
    "print(train_df[(train_df[\"ethnicity\"] == 0) & (train_df[\"efs\"] == 0)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22922, 58)\n"
     ]
    }
   ],
   "source": [
    "part_1 = train_df[(train_df[\"ethnicity\"] == 1) & (train_df[\"efs\"] == 1)]\n",
    "part_2 = train_df[(train_df[\"ethnicity\"] == 1) & (train_df[\"efs\"] == 0)]\n",
    "part_3 = train_df[(train_df[\"ethnicity\"] == 0) & (train_df[\"efs\"] == 1)]\n",
    "part_4 = train_df[(train_df[\"ethnicity\"] == 0) & (train_df[\"efs\"] == 0)]\n",
    "\n",
    "part_1_downsampled = resample(part_1, replace=False, n_samples=len(part_2), random_state=42)\n",
    "part_4_upsampled = resample(part_4, replace=True, n_samples=len(part_3), random_state=42)\n",
    "\n",
    "# part_1_downsampled = resample(part_1, replace=False, n_samples=len(part_4), random_state=42)\n",
    "# part_2_downsampled = resample(part_2, replace=False, n_samples=len(part_4), random_state=42)\n",
    "# part_3_downsampled = resample(part_3, replace=False, n_samples=len(part_4), random_state=42)\n",
    "\n",
    "train_df_balanced = pd.concat([part_1_downsampled, part_2, part_3, part_4_upsampled])\n",
    "\n",
    "# train_df_balanced = pd.concat([part_1_downsampled, part_2_downsampled, part_3_downsampled, part_4])\n",
    "\n",
    "train_df_balanced = train_df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "print(train_df_balanced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df_balanced = train_df_balanced.iloc[:, :-1]\n",
    "y_train_df_balanced = train_df_balanced.iloc[:, -1]\n",
    "\n",
    "X_train_balanced = X_train_df_balanced.to_numpy()\n",
    "y_train_balanced = y_train_df_balanced.to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.909903201787044"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_1 = LogisticRegression(C=1, max_iter=1000, random_state=42)\n",
    "new_model_1.fit(X_train_balanced, y_train_balanced)\n",
    "y_pred = new_model_1.predict(X_test)\n",
    "\n",
    "z_test = (X_test[:, sensitive_attribute] == 1)\n",
    "\n",
    "positive_pred_z_0 = np.mean(y_pred[z_test == 0])\n",
    "positive_pred_z_1 = np.mean(y_pred[z_test == 1])\n",
    "\n",
    "parity = positive_pred_z_0 / positive_pred_z_1\n",
    "parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5606936416184971, 0.691734921816828, 0.3384615384615385, 0.3760217983651226)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_test = (X_test[:, sensitive_attribute] == 1)\n",
    "\n",
    "tp_0 = np.sum((y_pred == 1) & (y_test == 1) & (z_test == 0))\n",
    "fn_0 = np.sum((y_pred == 0) & (y_test == 1) & (z_test == 0))\n",
    "fp_0 = np.sum((y_pred == 1) & (y_test == 0) & (z_test == 0))\n",
    "tn_0 = np.sum((y_pred == 0) & (y_test == 0) & (z_test == 0))\n",
    "\n",
    "tp_1 = np.sum((y_pred == 1) & (y_test == 1) & (z_test == 1))\n",
    "fn_1 = np.sum((y_pred == 0) & (y_test == 1) & (z_test == 1))\n",
    "fp_1 = np.sum((y_pred == 1) & (y_test == 0) & (z_test == 1))\n",
    "tn_1 = np.sum((y_pred == 0) & (y_test == 0) & (z_test == 1))\n",
    "\n",
    "TPR_0 = tp_0 / (tp_0 + fn_0)\n",
    "TPR_1 = tp_1 / (tp_1 + fn_1)\n",
    "\n",
    "FPR_0 = fp_0 / (fp_0 + tn_0)\n",
    "FPR_1 = fp_1 / (fp_1 + tn_1)\n",
    "\n",
    "TPR_0, TPR_1, FPR_0, FPR_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we try reweighting method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight\n",
      "2.000663     12063\n",
      "2.419449      9975\n",
      "16.240915     1486\n",
      "39.563934      610\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "group_counts = train_df.groupby([\"ethnicity\", \"efs\"]).size()\n",
    "group_probs = group_counts / len(train_df)\n",
    "\n",
    "def compute_weight(row):\n",
    "    return 1 / group_probs[(row[\"ethnicity\"], row[\"efs\"])]\n",
    "\n",
    "train_df[\"weight\"] = train_df.apply(compute_weight, axis=1)\n",
    "print(train_df[\"weight\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df_reweighted = train_df.drop(columns=[\"efs\", \"weight\"])\n",
    "y_train_df_reweighted = train_df[\"efs\"]\n",
    "sample_weights = train_df[\"weight\"]\n",
    "\n",
    "X_train_reweighted = X_train_df_reweighted.to_numpy()\n",
    "y_train_reweighted = y_train_df_reweighted.to_numpy().ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.019169773172427"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model_2 = LogisticRegression(C=1, max_iter=1000, random_state=42)\n",
    "new_model_2.fit(X_train_reweighted, y_train_reweighted, sample_weight=sample_weights)\n",
    "y_pred = new_model_2.predict(X_test)\n",
    "\n",
    "z_test = (X_test[:, sensitive_attribute] == 1)\n",
    "\n",
    "positive_pred_z_0 = np.mean(y_pred[z_test == 0])\n",
    "positive_pred_z_1 = np.mean(y_pred[z_test == 1])\n",
    "\n",
    "parity = positive_pred_z_0 / positive_pred_z_1\n",
    "parity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6069364161849711,\n",
       " 0.684288905435592,\n",
       " 0.4153846153846154,\n",
       " 0.37329700272479566)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_test = (X_test[:, sensitive_attribute] == 1)\n",
    "\n",
    "tp_0 = np.sum((y_pred == 1) & (y_test == 1) & (z_test == 0))\n",
    "fn_0 = np.sum((y_pred == 0) & (y_test == 1) & (z_test == 0))\n",
    "fp_0 = np.sum((y_pred == 1) & (y_test == 0) & (z_test == 0))\n",
    "tn_0 = np.sum((y_pred == 0) & (y_test == 0) & (z_test == 0))\n",
    "\n",
    "tp_1 = np.sum((y_pred == 1) & (y_test == 1) & (z_test == 1))\n",
    "fn_1 = np.sum((y_pred == 0) & (y_test == 1) & (z_test == 1))\n",
    "fp_1 = np.sum((y_pred == 1) & (y_test == 0) & (z_test == 1))\n",
    "tn_1 = np.sum((y_pred == 0) & (y_test == 0) & (z_test == 1))\n",
    "\n",
    "TPR_0 = tp_0 / (tp_0 + fn_0)\n",
    "TPR_1 = tp_1 / (tp_1 + fn_1)\n",
    "\n",
    "FPR_0 = fp_0 / (fp_0 + tn_0)\n",
    "FPR_1 = fp_1 / (fp_1 + tn_1)\n",
    "\n",
    "TPR_0, TPR_1, FPR_0, FPR_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we use post-processing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lower TPR group: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2444/2444 [00:02<00:00, 1055.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.46719795211756576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def compute_rates(y_true, y_scores, threshold):\n",
    "    y_scores = np.array(y_scores)\n",
    "    preds = (y_scores >= threshold).astype(int)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, preds).ravel()\n",
    "    tpr = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    return tpr, fpr\n",
    "\n",
    "\n",
    "y_pred_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "z_test_0 = np.where(X_test[:, sensitive_attribute] == 0)[0]\n",
    "z_test_1 = np.where(X_test[:, sensitive_attribute] == 1)[0]\n",
    "\n",
    "\n",
    "def get_optimal_threshold(y_true_0, scores_0, y_true_1, scores_1, base_thresh=0.5):\n",
    "    tpr_0, _ = compute_rates(y_true_0, scores_0, base_thresh)\n",
    "    tpr_1, _ = compute_rates(y_true_1, scores_1, base_thresh)\n",
    "\n",
    "    if tpr_0 == tpr_1:\n",
    "        return base_thresh\n",
    "\n",
    "    if tpr_0 < tpr_1:\n",
    "        print(\"Lower TPR group: 0\")\n",
    "        y_lower_group = y_true_0\n",
    "        scores_lower_group = scores_0\n",
    "        fixed_tpr = tpr_1\n",
    "    else:\n",
    "        print(\"Lower TPR group: 1\")\n",
    "        y_lower_group = y_true_1\n",
    "        scores_lower_group = scores_1\n",
    "        fixed_tpr = tpr_0\n",
    "\n",
    "    min_diff = float(\"inf\")\n",
    "    optimal_thresh = base_thresh\n",
    "\n",
    "    thresholds = sorted(set(scores_lower_group), reverse=True)\n",
    "    for thresh in tqdm(thresholds, total=len(thresholds)):\n",
    "        new_tpr, _ = compute_rates(y_lower_group, scores_lower_group, thresh)\n",
    "        if abs(new_tpr - fixed_tpr) < min_diff:\n",
    "            optimal_thresh = thresh\n",
    "            min_diff = abs(new_tpr - fixed_tpr)\n",
    "\n",
    "    return optimal_thresh\n",
    "\n",
    "\n",
    "optimal_threshold = get_optimal_threshold(y_test[z_test_0], y_pred_probs[z_test_0], y_test[z_test_1], y_pred_probs[z_test_1])\n",
    "print(f\"Optimal Threshold: {optimal_threshold}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted TPR_0: 0.8323699421965318, Adjusted FPR_0: 0.7076923076923077\n",
      "Adjusted TPR_1: 0.8324646314221892, Adjusted FPR_1: 0.5386012715712988\n"
     ]
    }
   ],
   "source": [
    "tpr_0, fpr_0 = compute_rates(y_test[z_test_0], y_pred_probs[z_test_0], 0.5)\n",
    "tpr_1, fpr_1 = compute_rates(y_test[z_test_1], y_pred_probs[z_test_1], optimal_threshold)\n",
    "\n",
    "print(f\"Adjusted TPR_0: {tpr_0}, Adjusted FPR_0: {fpr_0}\")\n",
    "print(f\"Adjusted TPR_1: {tpr_1}, Adjusted FPR_1: {fpr_1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
