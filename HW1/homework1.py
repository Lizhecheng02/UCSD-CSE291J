# -*- coding: utf-8 -*-
"""homework1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10s0fXoatZe-3OywOXTeLCR-SUCdUJIT6

# Homework 1: Regression and classification

## Regression: download the steam dataset:
https://cseweb.ucsd.edu/classes/fa24/cse258-b/files/steam.json.gz

Experiments in this section will only use the “time played” (d[“hours”]) and the length of the review text (len(d[“text”)]).
"""

import gzip

z = gzip.open("steam.json.gz")
dataset = []
for l in z:
    d = eval(l)
    dataset.append(d)

len(dataset), dataset[0]

""" - Implement regression on time played (hours) using the length of the review and a bias term. Use an 80%/20% training/test split. Use sklearn’s linear_model.LinearRegression. Report the MSE on the test set."""

import numpy as np

X = np.array([len(row["text"]) for row in dataset]).reshape(-1, 1)
y = np.array([row["hours"] for row in dataset])
print(X.shape, y.shape)

X_train, y_train = X[:int(0.8 * len(X))], y[:int(0.8 * len(y))]
X_test, y_test = X[int(0.8 * len(X)):], y[int(0.8 * len(y)):]
print(X_train.shape, X_test.shape)

from sklearn.linear_model import LinearRegression

model = LinearRegression()
model.fit(X_train, y_train)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error

y_pred = model.predict(X_test)

q1_mse = mean_squared_error(y_true=y_test, y_pred=y_pred)
q1_mse

"""- Delete outliers from the training set. Keep the bottom 90% of time played values. Report the MSE on the test set, as well as the MAE on the test set."""

def delete_outliers(X, y, percentile=90):
    threshold = np.percentile(y, percentile)
    return X[y <= threshold], y[y <= threshold]

X_train_without_outliers, y_train_without_outliers = delete_outliers(X_train, y_train)
print(X_train_without_outliers.shape)

model = LinearRegression()
model.fit(X_train_without_outliers, y_train_without_outliers)

y_pred = model.predict(X_test)

q2_mse = mean_squared_error(y_true=y_test, y_pred=y_pred)
q2_mse

from sklearn.metrics import mean_absolute_error

y_pred = model.predict(X_test)

q2_mae = mean_absolute_error(y_true=y_test, y_pred=y_pred)
q2_mae

"""- Transform the target variable by taking log_2(y + 1). After performing regression on the test set, invert the transform (so that your model still predicts a number of hours), and report the MSE on the test set."""

def trans(y):
    return np.log2(y + 1)

# Invert the transformation
def inv_trans(y):
    return (2 ** y) - 1

y_train_trans = trans(y_train)

model = LinearRegression()
model.fit(X_train, y_train_trans)

y_pred = model.predict(X_test)
y_pred = inv_trans(y_pred)

q3_mse = mean_squared_error(y_true=y_test, y_pred=y_pred)
q3_mse

q3_mae = mean_absolute_error(y_true=y_test, y_pred=y_pred)
q3_mae

"""- Build a regressor that optimizes the MAE rather than the MSE (see e.g. https://stackoverflow.com/questions/71534025/how-mae-loss-is-optimized-with-sgd-optimizer-in-sklearn). Report the MSE and the MAE on the test set"""

from sklearn.linear_model import SGDRegressor

model = SGDRegressor(
    loss="epsilon_insensitive",
    epsilon=0,
    random_state=1
)

model.fit(X_train, y_train)
y_pred = model.predict(X_test)

q4_mse = mean_squared_error(y_true=y_test, y_pred=y_pred)
q4_mse

q4_mae = mean_absolute_error(y_true=y_test, y_pred=y_pred)
q4_mae

"""## Classification:

download the German Credit dataset: https://archive.ics.uci.edu/dataset/144/statlog+german+credit+data

- Implement a logistic regressor (sklearn’s linear_model.LogisticRegression) to predict the target variable (credit = good). Implement a 80/20 training/test split. Use a regularization value of C = 1. Report the accuracy and TPR on the test set.
"""

from sklearn.metrics import accuracy_score, confusion_matrix
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

def tpr_fpr(y_true, y_pred):
    cm = confusion_matrix(y_true, y_pred)
    TN, FP, FN, TP = cm.ravel()
    TPR = TP / (TP + FN)
    FPR = FP / (FP + TN)
    return TPR, FPR

german_credit = np.loadtxt("german.data-numeric")
attrs = german_credit[:, :-1]
labels = 2 - german_credit[:, -1] # (1 = Good,  2 = Bad) -> (0 = Bad, 1 = good)

X_train, y_train = attrs[:int(0.8 * len(attrs))], labels[:int(0.8 * len(labels))]
X_test, y_test = attrs[int(0.8 * len(attrs)):], labels[int(0.8 * len(labels)):]

model = LogisticRegression(C=1, max_iter=1000)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

q5_acc = accuracy_score(y_true=y_test, y_pred=y_pred)
q5_tpr, q5_fpr = tpr_fpr(y_true=y_test, y_pred=y_pred)
q5_acc, q5_tpr, q5_fpr

"""For the following, treat “foreign worker” as the “sensitive attribute” i.e., z=1 for foreign workers and z=0 for others.

- Report the TPR for Z=0 and Z=1.
"""

z = (attrs[:, 19] == 1).astype(int)
z_test = z[-len(y_test):]

def tpr(y_true, y_pred, z, category):
    indices = (z == category)
    y_true = y_true[indices]
    y_pred = y_pred[indices]
    cm = confusion_matrix(y_true, y_pred)
    TN, FP, FN, TP = cm.ravel()
    TPR = TP / (TP + FN)
    return TPR

z_0_TPR = tpr(y_true=y_test, y_pred=y_pred, z=z_test, category=0)
z_1_TPR = tpr(y_true=y_test, y_pred=y_pred, z=z_test, category=1)
z_0_TPR, z_1_TPR

"""- By changing the classifier thresholds, generate an ROC curve for your classifier. Report the TPR when the FPR is (as close as possible to) 0.8."""

from sklearn.metrics import roc_curve, auc

y_probs = model.predict_proba(X_test)[:, 1]

fpr, tpr, thresholds = roc_curve(y_true=y_test, y_score=y_probs)

fpr_threshold = 0.8
index = (np.abs(fpr - fpr_threshold)).argmin()
q7_tpr = tpr[index]
q7_tpr

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label="ROC Curve")
plt.scatter(fpr[index], tpr[index], color="red", label=f"FPR={fpr[index]:.2f}, TPR={tpr[index]:.2f}")
plt.axvline(x=fpr_threshold, color="green", linestyle="--", label=f"FPR Threshold = {fpr_threshold}")
plt.xlabel("False Positive Rate (FPR)")
plt.ylabel("True Positive Rate (TPR)")
plt.title("ROC Curve")
plt.legend()
plt.grid()
plt.show()

"""- Use an instance weighting approach (this option is already available in the library implementation) to tune the model such that instances with z=0 have 5x the instance weight of instances with z=1. Report the TPR for Z=0 and Z=1."""

def tpr(y_true, y_pred, z, category):
    indices = (z == category)
    y_true = y_true[indices]
    y_pred = y_pred[indices]
    cm = confusion_matrix(y_true, y_pred)
    TN, FP, FN, TP = cm.ravel()
    TPR = TP / (TP + FN)
    return TPR

z = (attrs[:, 19] == 1).astype(int)
weights = np.where(z == 0, 5, 1)[:len(y_train)]

weighted_model = LogisticRegression(C=1, max_iter=1000)
weighted_model.fit(X_train, y_train, sample_weight=weights)

y_pred_weighted = weighted_model.predict(X_test)

z_0_TPR_weighted = tpr(y_true=y_test, y_pred=y_pred_weighted, z=z_test, category=0)
z_1_TPR_weighted = tpr(y_true=y_test, y_pred=y_pred_weighted, z=z_test, category=1)

z_0_TPR_weighted, z_1_TPR_weighted

"""- (harder, 2 marks) Implement a support vector machine (using sklearn). Using your solution from question Q5, generate ROC curves for both the logistic regression model and the support vector machine. Find the point on this curve where the two models intersect, and report the corresponding TPR/FPR values."""

from sklearn.svm import SVC

svm = SVC(probability=True, C=1, max_iter=1000)
svm.fit(X_train, y_train)

svm_probas = svm.predict_proba(X_test)[:, 1]
svm_roc_fpr, svm_roc_tpr, svm_roc_thresholds = roc_curve(y_true=y_test, y_score=svm_probas)

lr_probas = model.predict_proba(X_test)[:, 1]
lr_roc_fpr, lr_roc_tpr, lr_roc_thresholds = roc_curve(y_true=y_test, y_score=lr_probas)

print(len(svm_roc_fpr), len(lr_roc_fpr))

intersection_points = []

for i, (lfpr, ltpr) in enumerate(zip(lr_roc_fpr, lr_roc_tpr)):
    for j, (sfpr, stpr) in enumerate(zip(svm_roc_fpr, svm_roc_tpr)):
        if np.isclose(lfpr, sfpr) and np.isclose(ltpr, stpr):
            intersection_points.append((lfpr, ltpr))

if intersection_points:
    print("Intersection Points:")
    for point in intersection_points:
        print(f"FPR: {point[0]: .4f}, TPR: {point[1]: .4f}")
else:
    print("No exact intersection points found.")

plt.figure(figsize=(10, 6))
plt.plot(lr_roc_fpr, lr_roc_tpr, label="Logistic Regression ROC")
plt.plot(svm_roc_fpr, svm_roc_tpr, label="SVM ROC")
for point in intersection_points:
    plt.scatter(point[0], point[1], color="red", label=f"Intersection: FPR={point[0]: .3f}, TPR={point[1]: .3f}")
plt.xlabel("False Positive Rate (FPR)")
plt.ylabel("True Positive Rate (TPR)")
plt.title("ROC Curves")
plt.legend()
plt.grid()
plt.show()

fpr_q9, tpr_q9 = intersection_points[2][0], intersection_points[2][1]
fpr_q9, tpr_q9

"""## Answers"""

answers = {
    "Q1": q1_mse,          # MSE
    "Q2": [q2_mse, q2_mae], # MSE, MAE
    "Q3": q3_mse,          # MSE
    "Q4": [q4_mse, q4_mae], # MSE, MAE
    "Q5": [q5_acc, q5_tpr], # Accuracy, TPR
    "Q6": [z_0_TPR, z_1_TPR], # TPR_0, TPR_1
    "Q7": q7_tpr,          # TPR
    "Q8": [z_0_TPR_weighted, z_1_TPR_weighted], # TPR_0, TPR_1
    "Q9": [tpr_q9, fpr_q9]  # TPR, FPR
}

answers